{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!kaggle datasets download -d 'ashikadnan/railway-track-fault-detection-dataset1-rail'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!unzip railway-track-fault-detection-dataset1-rail.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import Xception\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "CONFIG = {\n",
    "    'IMG_HEIGHT': 299,\n",
    "    'IMG_WIDTH': 299,\n",
    "    'BATCH_SIZE': 32,\n",
    "    'EPOCHS': 50,\n",
    "    'BASE_DIR': '/content/dataset/',\n",
    "    'TRAIN_DIR': os.path.join('/content/dataset/', 'Train'),\n",
    "    'VALIDATE_DIR': os.path.join('/content/dataset/', 'Validation')\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_data_generators():\n",
    "    train_datagen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        rotation_range=20,\n",
    "        width_shift_range=0.2,\n",
    "        height_shift_range=0.2,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True,\n",
    "        fill_mode='nearest'\n",
    "    )\n",
    "\n",
    "    validation_datagen = ImageDataGenerator(rescale=1./255)\n",
    "    \n",
    "    return train_datagen, validation_datagen\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    base_model = Xception(\n",
    "        weights='imagenet',\n",
    "        include_top=False,\n",
    "        input_shape=(CONFIG['IMG_HEIGHT'], CONFIG['IMG_WIDTH'], 3)\n",
    "    )\n",
    "    \n",
    "    x = base_model.output\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Dense(1024, activation='relu')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    predictions = Dense(1, activation='sigmoid')(x)\n",
    "    \n",
    "    model = Model(inputs=base_model.input, outputs=predictions)\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer='adam',\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model():\n",
    "    # Create generators\n",
    "    train_datagen, validation_datagen = create_data_generators()\n",
    "    \n",
    "    train_generator = train_datagen.flow_from_directory(\n",
    "        CONFIG['TRAIN_DIR'],\n",
    "        target_size=(CONFIG['IMG_HEIGHT'], CONFIG['IMG_WIDTH']),\n",
    "        batch_size=CONFIG['BATCH_SIZE'],\n",
    "        class_mode='binary'\n",
    "    )\n",
    "    \n",
    "    validation_generator = validation_datagen.flow_from_directory(\n",
    "        CONFIG['VALIDATE_DIR'],\n",
    "        target_size=(CONFIG['IMG_HEIGHT'], CONFIG['IMG_WIDTH']),\n",
    "        batch_size=CONFIG['BATCH_SIZE'],\n",
    "        class_mode='binary'\n",
    "    )\n",
    "    \n",
    "    # Create model\n",
    "    model = create_model()\n",
    "    \n",
    "    # Define callbacks\n",
    "    callbacks = [\n",
    "        EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True),\n",
    "        ModelCheckpoint('best_model.h5', monitor='val_loss', save_best_only=True),\n",
    "        ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=3, min_lr=1e-7)\n",
    "    ]\n",
    "    \n",
    "    # Train model\n",
    "    history = model.fit(\n",
    "        train_generator,\n",
    "        validation_data=validation_generator,\n",
    "        epochs=CONFIG['EPOCHS'],\n",
    "        steps_per_epoch=train_generator.samples // CONFIG['BATCH_SIZE'],\n",
    "        validation_steps=validation_generator.samples // CONFIG['BATCH_SIZE'],\n",
    "        callbacks=callbacks\n",
    "    )\n",
    "    \n",
    "    return model, history, validation_generator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_training_history(history):\n",
    "    \"\"\"\n",
    "    Plot training & validation accuracy and loss values\n",
    "    \n",
    "    Args:\n",
    "        history: Keras history object containing training history\n",
    "    \"\"\"\n",
    "    # Create figure with 2 subplots\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
    "    \n",
    "    # Plot accuracy\n",
    "    ax1.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "    ax1.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "    ax1.set_title('Model Accuracy')\n",
    "    ax1.set_xlabel('Epoch')\n",
    "    ax1.set_ylabel('Accuracy')\n",
    "    ax1.legend(loc='lower right')\n",
    "    ax1.grid(True)\n",
    "    \n",
    "    # Plot loss\n",
    "    ax2.plot(history.history['loss'], label='Training Loss')\n",
    "    ax2.plot(history.history['val_loss'], label='Validation Loss')\n",
    "    ax2.set_title('Model Loss')\n",
    "    ax2.set_xlabel('Epoch')\n",
    "    ax2.set_ylabel('Loss')\n",
    "    ax2.legend(loc='upper right')\n",
    "    ax2.grid(True)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Save the plot\n",
    "    fig.savefig('training_history.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def plot_confusion_matrix(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Plot confusion matrix for binary classification\n",
    "    \n",
    "    Args:\n",
    "        y_true: Ground truth labels\n",
    "        y_pred: Predicted labels\n",
    "    \"\"\"\n",
    "    # Calculate confusion matrix\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    \n",
    "    # Create figure\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    \n",
    "    # Plot confusion matrix using seaborn\n",
    "    sns.heatmap(\n",
    "        cm, \n",
    "        annot=True, \n",
    "        fmt='d', \n",
    "        cmap='Blues',\n",
    "        xticklabels=['No Crack', 'Crack'],\n",
    "        yticklabels=['No Crack', 'Crack']\n",
    "    )\n",
    "    \n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.ylabel('True Label')\n",
    "    plt.xlabel('Predicted Label')\n",
    "    \n",
    "    # Save the plot\n",
    "    plt.savefig('confusion_matrix.png')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, history, validation_generator):\n",
    "    # Plot training history\n",
    "    plot_training_history(history)\n",
    "    \n",
    "    # Evaluate model\n",
    "    test_loss, test_accuracy = model.evaluate(validation_generator)\n",
    "    print(f\"\\nTest accuracy: {test_accuracy:.4f}\")\n",
    "    print(f\"Test loss: {test_loss:.4f}\")\n",
    "    \n",
    "    # Generate predictions and confusion matrix\n",
    "    predictions = model.predict(validation_generator)\n",
    "    y_pred = (predictions > 0.5).astype(int)\n",
    "    y_true = validation_generator.classes\n",
    "    \n",
    "    plot_confusion_matrix(y_true, y_pred)\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(y_true, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    for gpu in gpus:\n",
    "        tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    \n",
    "    # Train model\n",
    "model, history, validation_generator = train_model()\n",
    "    \n",
    "    # Evaluate results\n",
    "evaluate_model(model, history, validation_generator)\n",
    "    \n",
    "    # Save final model\n",
    "model.save('railmodel.h5')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
